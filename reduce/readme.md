## 1 性能指标的选择

选择有效带宽作为性能指标：假设数据量为N，那么最理想情况下，做reduce操作需要N次读和1次写，即N+1次访存，需要N-1次计算，假设数据类型为fp32，那么计算访存比为$$\frac{(N-1)}{4(N+1)}$$，约等于1比4。也就是说，fp32峰值性能和带宽峰值性能需要是1比4才能匹配这个计算强度，而在现实世界，往往是计算性能远大于带宽性能的，所以reduce算子是一个访存密集型算子，其目标是在上述的带宽资源有限的条件下，尽可能提升带宽的利用率。因此选择有效带宽作为性能指标。

## 2 计算有效带宽

对于fp32的reduce来说，有效带宽为$$\frac{4N}{time}$$。很容易理解，我们需要的就是将这N个数读进来（这里忽略了写），如果代码写得不好的话，可能会存在许多重复读取同一个位置的数据，这样的带宽利用率就不会是最理想的。

## 3 计算reduce结果

有两种方法可以计算reduce的结果：

1. 使用原子函数。每个block计算出来的结果用原子函数累加起来。

2. 启动两次kernel。首先启动一次多个block的kernel，每个block获得一个部分结果，并保存在一个连续的数组a中；然后再对数据a做一次reduce，且启动kernel时，只使用1个block，从而计算得到最终的结果。**该方法在数据量大的情况下结果更精确。**

- 为了方便，本文使用原子函数。

## 4 优化

### 4.0 测试结果

测试环境：V100 GPU，peak bandwidth约为900GB/s

|kernel|bandwidth (GB/s)|% of peak bandwidth||
|-|-|-|-|
|0 naive|243.221|30.4%||
|1 消除control diverge|472.763|52.5%|此方法顺便使得使用shared mem时不会存在bank conflict|
|2 使用shared mem|643.639|71.5%||
|3 thread coarsening|862.892|95.9%||
|4 warp reduce|864.324|96.0%|展开warp，用更细粒度的warp的同步方法代替sync thread，更细粒度意味着开销更小。从结果上看作用并不明显。|
|5 block reduce|865.483|96.2%||
|6 shuffle|866.35|96.3%|一个warp中的数据交换可以直接通过shuffle操作，实现寄存器层面的数据交换，不需要经过共享内存，从而进一步提升性能。|



